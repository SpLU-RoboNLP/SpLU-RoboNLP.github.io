<!DOCTYPE html>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>SpLU-RoboNLP 2019 by   </title>
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link
    href='http://fonts.googleapis.com/css?family=Open+Sans:400,700'
rel='stylesheet' type='text/css'>
<link rel="stylesheet"
    href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
    integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7"
crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css"
href="stylesheets/github-light.css" media="screen">


  </head>
  <body>

  <section class="page-header">

      <h1 class="project-name">SpLU-RoboNLP 2019</h1>
      <h2 class="project-tagline">Combined Workshop on Spatial Language Understanding (SpLU) and Grounded Communication for Robotics (RoboNLP)</h2>
<h2  class="project-tagline">In conjunction with The 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies <a href="http://naacl2019.org">(NAACL-HLT 2019)</a>, June 6/7 (TBD), 2019, Minneapolis, USA.
<br>
<br>
Room: TBA
<br>
</h2>
<br>

  </section>

  <section>
  <!-- Static navbar -->
      <nav class="navbar navbar-default">
        <div class="container-fluid">
          <div class="navbar-header">
            <butfton type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

          </div>
          <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li class="active"><a href="#overview">Overview</a></a></li>
              <li><a href="#invitedSpeakers">Invited Speakers</a></li>
              <li><a href="#submission-info">Submission</a></li>
         <li><a href="#important-dates">Important Dates</a></li>
              <!--li><a href="#demos">Demos</a></li-->
              <!--li><a href="#panel">Panel</a></li-->
              <!--li><a href="#submission-info">Submission</a></li-->
              <li><a href="#organizers">Organizers</a></li>
         <li><a href="#program-commitee">Program Committee</a></li>
         <li><a href="#pastworkshops">Past Workshops</a></li>
         </ul>
            </div><!--/.nav-collapse -->
        </div><!--/.container-fluid -->
      </nav>

   </section>

   <section class="main-content">

<h2>Overview</h2>

<p>
SpLU-RoboNLP 2019 is a combined workshop on spatial language understanding (SpLU) and grounded communication for robotics (RoboNLP) that focuses on spatial language, its linguistic and theoretical aspects as well as its application to various areas including and especially focusing on robotics. Both SpLU and RoboNLP have been offered before and received a lot of interest from researchers working on spatial language and robotics (<a href="https://spatial-language.github.io/old_SpLU_workshops/SpLU_2018/"> SpLU 2018</a>, <a href="---"> Robo-NLP 2017</a>). The combined workshop aims to bring together members of NLP, robotics, vision and related communities in order to initiate discussions across fields dealing with spatial language along with other modalities. The desired outcome is identification of shared as well as unique challenges, problems and future directions across the fields and various application domains related to spatial language understanding. </p>

<p>One of the essential functions of natural language is to express spatial relationships between objects. Linguistic constructs can encode highly complex, relational structures of objects, spatial relations between them, and patterns of motion through space relative to some reference point. Spatial language understanding is useful in many areas of research endeavors relating to and/or making use of human language, including robotics, navigation, geographic information systems, traffic management, natural language understanding and translation, and query answering systems. Compared to other semantically specialized linguistic tasks, standardizing tasks related to spatial language seems to be more challenging as it is harder to obtain an agreeable set of concepts and relationships and a formal spatial meaning representation that is domain independent. This has made research results on spatial language learning and reasoning diverse, task-specific and, to some extent, not comparable. While formal meaning representation is a general issue for language understanding, formalizing spatial concepts and building formal reasoning models based on those constitute challenging research problems with a wealth of prior foundational research that can be exploited and linked to language understanding. Attempts to arrive at a common set of basic concepts and relationships as well as making existing corpora inter-operable, however, can help avoid duplicated efforts within as well as across fields and instead focus on further developments in the respective fields for automatic learning and reasoning. </p>

<p>Existing qualitative and quantitative representation and reasoning models can be used for investigation of interoperabiltiy of machine learning and reasoning over spatial semantics. Research endeavors in this area could provide insights into many challenges of language understanding in general. Spatial semantics is also very well-connected and relevant to visualization of natural language and grounding language into perception, central to dealing with configurations in the physical world and motivating a combination of vision and language for richer spatial understanding. </p>

<p>Following the exciting recent progress in visual language grounding, the embodied, task-oriented aspect of language grounding is an important and timely research direction. To realize the long-term goal of robots that we can converse with in our homes, offices, hospitals, and warehouses, it is essential that we develop new techniques for linking language to action in the real world in which spatial language understanding plays a great role. Can we give instructions to robotic agents to assist with navigation and manipulation tasks in remote settings? Can we talk to robots about the surrounding visual world, and help them interactively learn the language needed to finish a task? We hope to learn about (and begin to answer) these questions as we delve deeper into spatial language understanding and grounding language for robotics. </p>

<p>The major topics covered in the workshop include: </p>

<ol>
<li> Spatial Language Meaning Representation (Continuous, Symbolic)</li>
<li> Spatial Language Learning </li>
<li> Spatial Language Reasoning </li>
<li> Combining Vision and Language for Spatial Understanding</li>
</ol>

<p>The specific topics include but are not limited to:</p>

<ul>
<li>Spatial meaning representations, continuous representations, ontologies, annotation schemes, linguistic corpora.</li>
<li>Spatial information extraction from natural language.</li>
<li>Spatial information extraction in robotics, multimodal environments, navigational instructions.</li>
<li>Text mining for spatial information in GIS systems, geographical knowledge graphs.</li>
<li>Spatial question answering, spatial information for visual question answering</li>
<li>Quantitative and qualitative reasoning with spatial information</li>
<li>Spatial reasoning based on natural language or multimodal information (vision and language)</li>
<li>Extraction of spatial common sense knowledge</li>
<li>Visualization of spatial language in 2-D and 3-D</li>
<li>Spatial natural language generation</li>
<li>Spatial language grounding, including the following:

<ul>
<li>Aligning and Translating Language to Situated Actions</li>
<li>Simulated and Real World Situations</li>
<li>Instructions for Navigation</li>
<li>Instructions for Articulation</li>
<li>Instructions for Manipulation</li>
<li>Skill Learning via Interactive Dialogue</li>
<li>Language Learning via Grounded Dialogue</li>
<li>Language Generation for Embodied Tasks</li>
<li>Grounded Knowledge Representations</li>
<li>Mapping Language and World</li>
<li>Grounded Reinforcement Learning</li>
<li>Language-based Game Playing for Grounding</li>
<li>Structured and Deep Learning Models for Embodied Language</li>
<li>New Datasets for Embodied Language</li>
<li>Better Evaluation Metrics for Embodied Language</li>
</ul>
</li>
</ul>
   </section>

<a id="invitedSpeakers" class="anchor" href="#invitedSpeakers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Invited Speakers</h2>

<ul>
 <li>
   <font size="3" color="black">Joyce Chai, Michigan State University</font>
   <br />
</li>
<li>
   <font size="3" color="black">TBA</font>
   <br/>
</li>
<li>
   <font size="3" color="black">TBA</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Dhruv Batra, GaTech/FAIR</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Anca Dragan, UC Berkeley</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Mary Ellen Foster, Glasgow University</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Dilek Hakkani-Tur, Amazon</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Cynthia Matuszek, UMBC</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Matthias Scheutz, Tufts</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Stefanie Tellex, Brown</font>
   <br/>
</li>
<li>
   <font size="3" color="black">Andrea Thomaz, UT Austin</font>
   <br/>
</li>
<li>
   <font size="3" color="black">David Traum, USC</font>
   <br/>
</li>

</ul>

<a id="submission-info" class="anchor" href="#submission-info" aria-hidden="true"><span class="octicon octicon-link"></span></a>
<h2>Submissions</h2>

We encourage contributions with either a technical paper (NAACL style, 8 pages without references), a position statement (NAACL style, 4 pages maximum) or an abstract of a published work. NAACL Style files available <a href="https://naacl2019.org/calls/papers">here</a>. Please make submissions via Softconf <a href=""> TBA here</a>.

 <a id="important-dates" class="anchor" href="#accepted-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Important Dates</h2>
 <ul>
  <li>Submission Deadline: 15 February 2019</li>
  <li>Notification: 1 March 2019</li>
  <li>Camera Ready deadline: 1 April 2019</li>
  <li>Workshop Day: 6/7 June, 2019</li>
 </ul>

<a id="organizers" class="anchor" href="#organizers" aria-hidden="true"><span class="octicon octicon-link"></span></a>

<h2>Organizing Committee</h2>

<table cellspacing="0" cellpadding="0" style="width:100%">
<tr>
<td>
 <li><a href="http://www.cs.tulane.edu/%7Epkordjam/">Parisa Kordjamshidi</a></td>
  <td>Tulane University, <a href="https://www.ihmc.us">IHMC</a></li></td>
  <td> pkordjam@tulane.edu</td>
</tr>

<tr>
<td>
 <li><a href="https://www.ihmc.us/groups/abhatia/">Archna Bhatia</a></td>
  <td><a href="https://www.ihmc.us">IHMC</a></li></td>
  <td> abhatia@ihmc.us</td>
</tr>

<tr>
<td>
 <li><a href="https://www.ihmc.us/groups/bdorr/">Bonnie J. Dorr</a></td>
  <td><a href="https://www.ihmc.us">IHMC</a></li></td>
  <td> bdorr@ihmc.us</td>
</tr>

<tr>
<td>
 <li><a href="http://www.cs.rochester.edu/~james/">James F. Allen</a></td>
  <td><a href="https://www.rochester.edu">University of Rochester</a>, <a href="https://www.ihmc.us">IHMC</a></li></td>
  <td> jallen@ihmc.us</td>
</tr>

<tr>
<td><li><a href="http://www.cs.rochester.edu/~james/"> James F. Allen</a></td>
<td><a href="https://www.rochester.edu">University of Rochester</a>, <a href="https://www.ihmc.us">IHMC</a></li></td>
<td>jallen@ihmc.us</td>
</tr>

<tr>
<td><li>Jacob Andreas</td>
<td>MIT</li></td>
<td>EMAIL</td>
</tr>

<tr>
<td><li>Jason Baldridge</td>
<td>Google</li></td>
<td>EMAIL</td>
</tr>

<tr>
<td><li>Mohit Bansal</td>
<td>UNC Chapel Hill</li></td>
<td>EMAIL</td>
</tr>

<tr>
<td><li>Yonatan Bisk</td>
<td>Univ of Washington</li></td>
<td>EMAIL</td>
</tr>

<tr>                         
<td><li>Asli Celikyilmaz</td>
<td>Microsoft Research</li></td>
<td>EMAIL</td>
</tr>
 
<tr>
<td><li>Jesse Thomason</td>
<td>Univ of Washington</li></td>
<td>EMAIL</td>
</tr>

<tr>
<td><li>Matthew Marge</td>
<td>Army Research Lab</li></td>
<td>EMAIL</td>
</tr>

</table>

<a id="program-commitee" class="anchor" href="#program-commitee" aria-hidden="true"><span class="octicon octicon-link"></span></a>

<h2>Program Committee</h2>
<div>
<table cellspacing="0" cellpadding="0" float="left">
<tr>
<td>
<li>Yoav Artzi</td> <td>Cornell University</td></li>
  </tr>
 <tr>
<td><li>Jason Baldridge</td><td>Google Inc. Mountain View CA</li></td>
</tr>
  <tr>
<td><li>John A. Bateman</td><td>Universität Bremen</td></li>
</tr>
<tr>
<td>
<li>Mehul Bhatt</td><td>Örebro University</td></li>
</tr>
<tr>
<td><li>Raffaella Bernardi</td><td>University of Trento</li></td>
</tr>
<tr>
<td><li>Steven Bethard</td><td>University of Arizona</li></td>
</tr>
<tr>
<td>
<li> Yonatan Bisk</td> <td>University of Washington</li></td>
</tr>
<tr>
<td><li>Johan Bos</td><td>University of Groningen</li></td>
</tr>
<tr>
<td><li>Guillem Collell</td><td> KU Leuven</li></td>
</tr>
<tr>
<td><li>Joyce Chai</td><td>Michigan State University</li></td>
</tr>
<tr>
<td><li>Simon Dobnik</td><td>CLASP and FLOV, University of Gothenburg Sweden</li></td>
</tr>
<tr>
<td><li>Ekaterina Egorova</td><td>University of Zurich</li></td>
</tr>
<tr>
<td><li>Zoe Falomir</td><td>Universität Bremen</li></td>
</tr>
<tr>
<td><li>Lucian Galescu</td><td>IHMC</li></td>
<tr>
<td><li>Julia Hockenmaier</td><td>University of Illinois at Urbana-Champaign</li></td>
</tr>
<tr>
<td><li>Bruno Martins</td><td>University of Lisbon</li></td>
</tr>
<tr>
<td><li>Srini Narayanan</td><td>Google Inc. Mountain View CA</li></td>
</tr>
<tr>
<td><li>Mari Broman Olsen</td><td>Microsoft</li></td>
</tr>
<tr>
<td><li>Martijn van Otterlo</td><td>Vrije Universiteit Amsterdam</li></td>
</tr>
<tr>
<td><li>Ian Perera</td><td>IHMC</li></td>
</tr>
<tr>
<td><li>Kirk Roberts</td><td>The University of Texas</li></td>
</tr>
<tr>
<td><li>Manolis Savva</td><td>Princeton University</li></td>
</tr>
<tr>
<td><li>Kristin Stock</td><td>Massey University of New Zeeland</li></td>
</tr>
<tr>
<td><li>Clare Voss</td><td>ARL</li></td>
</tr>
<tr>
<td><li>RoboNLP PC members TO BE ADDED</td><td> - AFFILIATION</li></td>
</tr>

 </tr>
</table>
</div>

<a id="pastworkshops" class="anchor" href="#pastworkshops" aria-hidden="true"><span class="octicon octicon-link"></span></a>
<h2>Past Workshops</h2>

<p>
<a href="https://spatial-language.github.io/old_SpLU_workshops/SpLU_2018/"> SpLU 2018</a>
</p>
<p><a href="https://robo-nlp.github.io/..."> Robo-NLP 2018</a>
</p>
</section>



</body>
</html>
